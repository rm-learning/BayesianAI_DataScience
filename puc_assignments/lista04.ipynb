{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìç **Quest√£o 1**\n",
    "\n",
    "Utilizando o algoritmo de Naive Bayes, qual a probabilidade de Jogar ou n√£o Jogar, respectivamente, para o registro?\n",
    "\n",
    "`Registro: aparencia - chuva (0), temperatura - fria (1), umidade - normal (1), ventando - sim (1)`\n",
    "\n",
    "> Probabilidade de N√£o Jogar ['nao']: 0.3571\n",
    "> \n",
    "> Probabilidade de Jogar ['sim']: 0.6428"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üìç **Quest√£o 2**\n",
    "\n",
    "Implemente o m√©todo de Naive Bayes utilizando o python. Veja a resposta do algoritmo para o registro.\n",
    "\n",
    "> A implementa√ß√£o do Naive Bayes est√° dispon√≠vel no reposit√≥rio [BayesianAI_DataScience](https://github.com/rm-learning/BayesianAI_DataScience), especificamente na pasta `src`; arquivo `ai01_wp_NaiveBayes.ipynb`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üìç**Quest√£o 3**\n",
    "\n",
    "Implemente o m√©todo de Random Forest utilizando o python. Utilize a base acima e compare o resultado deste m√©todo com o Naive Bayes e a √Årvore de decis√£o. Ajuste os hiperpar√¢metros, utilizando o GridSearch e RandomSearch. Fa√ßa uma an√°lise comparativa\n",
    "\n",
    "> Obtive resultados diferentes para o conjunto de dados weather_play.csv nas diferentes abordagens. O Naive Bayes assume que a presen√ßa de uma caracter√≠stica espec√≠fica n√£o se relaciona com qualquer outro recurso tamb√©m inserido no dataframe e, por isso, sua an√°lise estat√≠stica admite um resultado favor√°vel a 'jogar'. Por outro lado, o Random Forest para um total de 60 estimadores concluiu que 'n√£o jogar' seria a resposta adequada para o registro apresentado na quest√£o 1.\n",
    "\n",
    "> A implementa√ß√£o do Random Forest est√° dispon√≠vel no reposit√≥rio [EnsembleAI_DataScience](https://github.com/rm-learning/EnsembleAI_DataScience), especificamente na pasta `src`; arquivo `ai01_wp_RandomForest.ipynb` "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üìç **Quest√£o 4**\n",
    "\n",
    "A come√ßar pelo Bagging, o Bootstrap Agregating √© um m√©todo que constroi v√°rios modelos (normalmente √°rvores de decis√£o) em subconjuntos aleat√≥rios dos dados de treinamento e, em seguida, combina suas previs√µes por meio de m√©dia ou vota√ß√£o. Ele um usa um subconkunto de dados (bootstrap) para criar as √°rvores, mas todos os recursos podem ser usados para realizar as divis√µes, sendo bastante √∫til para as √°rvores de decis√£o.\n",
    "\n",
    "O Boosting, por sua vez, tem por objetivo principal treinar v√°rios modelos de aprendizado de m√°quina de forma sequencial. Cada modelo subsequente √© treinado para corrigir os erros cometidos pelos modelos anteriores. Ele usa todo o conjunto de dados para criar √°rvores (sem bootstrap), e todos os recursos podem ser usados para realizar as divis√µes.\n",
    "\n",
    "Por fim, a Random Forest combina v√°rias √°rvores de decis√£o para formar uma floresta. Assim ela usa um subconjunto do conjunto de dados (bootstrap) para criar √°rvores, e apenas subjconjuntos de recursos podem ser usados para realizar as divis√µes. V√°lido notar que a Random Forest geralmente supera o Bagging devido √† sua camada adicional de aleatoriedade durante a constru√ß√£o da √°rvore.\n",
    "\n",
    "> As implementa√ß√µes est√£o dispon√≠veis no reposit√≥rio [EnsembleAI_DataScience](https://github.com/rm-learning/EnsembleAI_DataScience), especificamente na pasta `src`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üìç **Quest√£o 5**\n",
    "\n",
    "Resumo do artigo [A Survey of Ensemble Learning Concepts Algorithms Applications and Prospect](https://pucminas.instructure.com/courses/160903/files/9487069?module_item_id=3662740) disponibilizado no canvas.\n",
    "\n",
    "> O artigo redigido por Domor e Yanxia trata sobre uma perspectiva geral do aprendizado em conjunto (Ensemble), uma t√©cnica que combina v√°rios modelos de aprendizado de m√°quina para obter um melhor desempenho e capacidade de generaliza√ß√£o. Nesse sentido, o artigo aborda os tr√™s principais m√©todos ensemble: bagging (Random Forest), boosting (AdaBoost, Gradient Boosting, XGBoost, LightGBM, CatBoost) e stacking, exibindo a maior parte do seu desenvolvimento, bem como suas respectivas representa√ß√µes matem√°ticas e algor√≠tmicas.\n",
    "> Al√©m disso, nas √∫ltimas se√ß√µes do artigo, h√° uma descri√ß√£o das mais recentes aplica√ß√µes do aprendizado ensemble na atualidade, o que inclui: diagn√≥stico m√©dico, detec√ß√£o de fraudes e a an√°lise de sentimentos. N√£o deixando de abordar as vantagens e limita√ß√µes desse tipo de aprendizado, bem como as dire√ß√µes futuras que a pesquisa nesse campo tem direcionado."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
